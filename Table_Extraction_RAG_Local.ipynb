{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rajaveljp/rajaveljp/blob/main/Table_Extraction_RAG_Local.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# End to End Implementation of Retrieval Augmented Generation (RAG) with Unstructured, LangChain and ChromaDB\n",
        "\n",
        "In the following python notebook we will go over how to extract tables from quarterly earnings reports using Unstructured's python library. We will then chunk, embedd and store the tables in a vector database for retrieval.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "dE5LqFAenEUM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install chromadb"
      ],
      "metadata": {
        "id": "FBm61GB5fiBf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install unstructured unstructured-inference"
      ],
      "metadata": {
        "id": "hJhLfReng1FH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai langchain"
      ],
      "metadata": {
        "id": "D2XAUYZ2hX72"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install poppler-utils\n",
        "!sudo apt-get install tesseract-ocr\n"
      ],
      "metadata": {
        "id": "HJkwfQW_jabx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uv0WuqDdk5qi",
        "outputId": "ec2f8a49-d61d-458f-9453-18ecb41cd6f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.6.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2023.7.22)\n",
            "Installing collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import pprint\n",
        "import openai\n",
        "import chromadb\n",
        "\n",
        "from chromadb.utils import embedding_functions\n",
        "from unstructured.partition.pdf import partition_pdf\n",
        "from unstructured.staging.base import elements_to_json\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings"
      ],
      "metadata": {
        "id": "OU4Q9wm5hdzw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filename = \"/Path/To/Your/File\" # For this notebook I uploaded Nvidia's earnings into Google Colab's files directory called \"/content/\"\n",
        "output_dir = \"/Path/To/Your/Desired/Output\" # I also put the output in the \"/content\" directory"
      ],
      "metadata": {
        "id": "eqqO86nehhzO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define parameters for Unstructured's library\n",
        "strategy = \"hi_res\" # Used for analyzing PDFs and extracting table structure\n",
        "model_name = \"yolox\" # Best model for table extraction. Other options are detectron2_onnx and chipper depending on file layout"
      ],
      "metadata": {
        "id": "iyc_rMfQhpY9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "elements = partition_pdf(filename=filename, strategy=strategy, infer_table_structure=True, model_name=model_name)"
      ],
      "metadata": {
        "id": "LzDaUGVuhqQv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "elements_to_json(elements, filename=f\"{filename}.json\") # Takes a while for file to show up on the Google Colab"
      ],
      "metadata": {
        "id": "lhj9-zZshr56"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_json_file(input_filename):\n",
        "    # Read the JSON file\n",
        "    with open(input_filename, 'r') as file:\n",
        "        data = json.load(file)\n",
        "\n",
        "    # Iterate over the JSON data and extract required table elements\n",
        "    extracted_elements = []\n",
        "    for entry in data:\n",
        "        if entry[\"type\"] == \"Table\":\n",
        "            extracted_elements.append(entry[\"metadata\"][\"text_as_html\"])\n",
        "\n",
        "    # Write the extracted elements to the output file\n",
        "    with open(\"/content/nvidia-yolox.txt\", 'w') as output_file:\n",
        "        for element in extracted_elements:\n",
        "            output_file.write(element + \"\\n\\n\")  # Adding two newlines for separation\n"
      ],
      "metadata": {
        "id": "Bcbki04ckemn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "process_json_file(f\"{filename}.json\") # Takes a while for the .txt file to show up in Colab"
      ],
      "metadata": {
        "id": "ir21NpPrkiH9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_file = \"/content/nvidia-yolox.txt\""
      ],
      "metadata": {
        "id": "tQm3kUkckjxv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loader = TextLoader(text_file)\n",
        "documents = loader.load()"
      ],
      "metadata": {
        "id": "-JMKvZmdkl0f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split it into chunks\n",
        "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "docs = text_splitter.split_documents(documents)"
      ],
      "metadata": {
        "id": "jNxhYrickmGV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['OPENAI_API_KEY'] = \"<YOUR-OPENAI-API-KEY>\"\n",
        "embeddings = OpenAIEmbeddings()"
      ],
      "metadata": {
        "id": "yAFqv7iakmhe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "db = Chroma.from_documents(docs, embeddings)"
      ],
      "metadata": {
        "id": "BizPDv_2k3pG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize your model and retriever\n",
        "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
        "qa_chain = RetrievalQA.from_chain_type(llm, retriever=db.as_retriever())\n",
        "\n",
        "# List of questions\n",
        "questions = [\n",
        "    \"How much revenue did Nvidia make in Q2 FY24?\",\n",
        "    \"What was the operating income for Q2 FY24?\",\n",
        "    \"How much was the net income in Q1 FY24?\",\n",
        "    \"What was the Q/Q revenue growth between Q1 and Q2 of FY24?\",\n",
        "    \"How much revenue did Nvidia's Data Center produce in Q2 FY24?\",\n",
        "    \"How much revenue did Nvidia's Gaming sector produce in Q2 FY24?\",\n",
        "    \"What percent of the total revenue in Q2 FY24 did Data Centers represent?\"\n",
        "]\n",
        "\n",
        "# Store responses in output_list\n",
        "output_list = []\n",
        "\n",
        "for query in questions:\n",
        "    response = qa_chain({\"query\": query})\n",
        "    output_list.append(response)"
      ],
      "metadata": {
        "id": "ndQVA2gMlBCw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use pprint to pretty print the output list\n",
        "pp = pprint.PrettyPrinter(indent=4)\n",
        "pp.pprint(output_list)"
      ],
      "metadata": {
        "id": "-6ZltYu5mJ6m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pO6VRAmAme_X"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}